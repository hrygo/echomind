package mock

import (
	"context"
	"time"

	"github.com/hrygo/echomind/pkg/ai"
)

type MockProvider struct{}

func NewProvider() *MockProvider {
	return &MockProvider{}
}

// AIProvider implementation

func (m *MockProvider) Summarize(ctx context.Context, text string) (ai.AnalysisResult, error) {
	return ai.AnalysisResult{
		Summary:     "This is a mock summary of the email.",
		Category:    "Work",
		Sentiment:   "Neutral",
		Urgency:     "Medium",
		ActionItems: []string{"Mock action item 1", "Mock action item 2"},
	}, nil
}

func (m *MockProvider) Classify(ctx context.Context, text string) (string, error) {
	return "Work", nil
}

func (m *MockProvider) AnalyzeSentiment(ctx context.Context, text string) (ai.SentimentResult, error) {
	return ai.SentimentResult{
		Sentiment: "Neutral",
		Urgency:   "Medium",
	}, nil
}

func (m *MockProvider) GenerateDraftReply(ctx context.Context, emailContent, userPrompt string) (string, error) {
	return "Dear User,\n\nThis is a mock reply generated by the system.\n\nBest regards,\nMock AI", nil
}

// EmbeddingProvider implementation

func (m *MockProvider) Embed(ctx context.Context, text string) ([]float32, error) {
	// Return a random vector of dimension 1536 (OpenAI standard) or similar
	// For simplicity, we return a small vector, but in real scenarios it should match the DB dimension.
	// Assuming 1536 dims for compatibility.
	vec := make([]float32, 1536)
	for i := range vec {
		vec[i] = 0.01 // Dummy value
	}
	// Simulate latency
	time.Sleep(100 * time.Millisecond)
	return vec, nil
}

func (m *MockProvider) EmbedBatch(ctx context.Context, texts []string) ([][]float32, error) {
	var results [][]float32
	for range texts {
		vec, _ := m.Embed(ctx, "")
		results = append(results, vec)
	}
	return results, nil
}
