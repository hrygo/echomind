# ğŸ” EchoMind å‘é‡æœç´¢æŠ€æœ¯æŒ‡å—

## æ¦‚è¿°

EchoMind çš„å‘é‡æœç´¢ç³»ç»ŸåŸºäº PostgreSQL + pgvector æ„å»ºï¼Œå®ç°äº†é«˜æ€§èƒ½çš„è¯­ä¹‰æœç´¢å’Œ RAG (Retrieval-Augmented Generation) åŠŸèƒ½ã€‚æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»äº†å‘é‡æœç´¢çš„æŠ€æœ¯å®ç°ã€æ€§èƒ½ä¼˜åŒ–å’Œæœ€ä½³å®è·µã€‚

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### å‘é‡æœç´¢æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç”¨æˆ·æŸ¥è¯¢      â”‚ -> â”‚  æ–‡æœ¬é¢„å¤„ç†      â”‚ -> â”‚  åµŒå…¥ç”Ÿæˆ       â”‚ -> â”‚  å‘é‡æœç´¢       â”‚
â”‚   "é¡¹ç›®è¿›å±•"     â”‚    â”‚  æ¸…æ´—ã€åˆ†å—      â”‚    â”‚  768/1024/1536  â”‚    â”‚  ç›¸ä¼¼åº¦è®¡ç®—     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç»“æœæ’åº      â”‚ <- â”‚  åˆ†æ•°è¿‡æ»¤       â”‚ <- â”‚  åå¤„ç†         â”‚ <- â”‚  æ•°æ®åº“æŸ¥è¯¢     â”‚
â”‚   ç›¸å…³æ€§æ’åº     â”‚    â”‚  é˜ˆå€¼è¿‡æ»¤       â”‚    â”‚  å»é‡ã€èšåˆ      â”‚    â”‚  è¿‘ä¼¼æœ€è¿‘é‚»     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶

#### 1. åµŒå…¥ç”ŸæˆæœåŠ¡ (`pkg/ai/embedding.go`)

```go
type EmbeddingService struct {
    provider ai.EmbeddingProvider
    cache    *redis.Client
    metrics  *prometheus.Registry
}

// æ‰¹é‡ç”ŸæˆåµŒå…¥ï¼Œæé«˜æ•ˆç‡
func (s *EmbeddingService) GenerateEmbeddings(ctx context.Context, texts []string) ([][]float32, error) {
    // 1. æ£€æŸ¥ç¼“å­˜
    cached := s.getCachedEmbeddings(texts)

    // 2. æ‰¹é‡ç”Ÿæˆæœªç¼“å­˜çš„
    uncached := s.getUncachedTexts(texts, cached)
    vectors, err := s.provider.EmbedBatch(ctx, uncached)

    // 3. ç¼“å­˜ç»“æœ
    s.cacheEmbeddings(uncached, vectors)

    // 4. åˆå¹¶ç»“æœ
    return s.mergeResults(cached, vectors), nil
}
```

#### 2. å‘é‡æœç´¢å¼•æ“ (`internal/service/search.go`)

```go
type SearchEngine struct {
    db          *gorm.DB
    embedder    ai.EmbeddingProvider
    cache       *redis.Client
    indexConfig *IndexConfig
}

// é«˜æ€§èƒ½å‘é‡æœç´¢
func (s *SearchEngine) SemanticSearch(ctx context.Context, req SearchRequest) (*SearchResponse, error) {
    // 1. æŸ¥è¯¢å‘é‡åŒ–
    queryVector, err := s.embedder.Embed(ctx, req.Query)

    // 2. æ„å»ºä¼˜åŒ–æŸ¥è¯¢
    sql := s.buildOptimizedQuery(req)

    // 3. æ‰§è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢
    var results []EmailEmbedding
    err = s.db.WithContext(ctx).Raw(sql,
        pgvector.NewVector(queryVector),
        req.UserID,
        req.Limit,
    ).Scan(&results).Error

    // 4. åå¤„ç†å’Œæ’åº
    return s.postProcessResults(results, req), nil
}
```

## ğŸ¯ å‘é‡æ•°æ®åº“ä¼˜åŒ–

### ç´¢å¼•ç­–ç•¥

#### 1. IVFFlat ç´¢å¼• (é€‚åˆä¸­ç­‰è§„æ¨¡æ•°æ®)

```sql
-- åˆ›å»º IVFFlat ç´¢å¼•
CREATE INDEX CONCURRENTLY email_embeddings_vector_idx
ON email_embeddings
USING ivfflat (vector vector_l2_ops)
WITH (lists = 100);

-- ç›‘æ§ç´¢å¼•æ•ˆæœ
EXPLAIN (ANALYZE, BUFFERS)
SELECT id, 1 - (vector <=> '[0.1,0.2,...]') as similarity
FROM email_embeddings
ORDER BY vector <=> '[0.1,0.2,...]'
LIMIT 20;
```

#### 2. HNSW ç´¢å¼• (é€‚åˆå¤§è§„æ¨¡æ•°æ®)

```sql
-- åˆ›å»º HNSW ç´¢å¼• (æ›´é«˜çš„å¬å›ç‡)
CREATE INDEX CONCURRENTLY email_embeddings_hnsw_idx
ON email_embeddings
USING hnsw (vector vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- è°ƒæ•´æŸ¥è¯¢æ—¶çš„ ef å‚æ•°ä»¥æé«˜ç²¾åº¦
SET hnsw.ef_search = 100;
```

### æ•°æ®åˆ†åŒºä¼˜åŒ–

```sql
-- æŒ‰æ—¶é—´åˆ†åŒºå‘é‡è¡¨
CREATE TABLE email_embeddings_2024_q1 PARTITION OF email_embeddings
FOR VALUES FROM ('2024-01-01') TO ('2024-04-01');

-- è‡ªåŠ¨åˆ›å»ºæ–°åˆ†åŒº
CREATE OR REPLACE FUNCTION create_monthly_partition()
RETURNS void AS $$
DECLARE
    start_date date;
    end_date date;
BEGIN
    start_date := date_trunc('month', CURRENT_DATE);
    end_date := start_date + interval '1 month';

    EXECUTE format('CREATE TABLE IF NOT EXISTS email_embeddings_%s PARTITION OF email_embeddings
                    FOR VALUES FROM (%L) TO (%L)',
                   to_char(start_date, 'YYYY_MM'),
                   start_date, end_date);
END;
$$ LANGUAGE plpgsql;
```

## âš¡ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. æŸ¥è¯¢ä¼˜åŒ–

#### ç¼“å­˜ç­–ç•¥

```go
type SearchCache struct {
    redis  *redis.Client
    local  *sync.Map
    ttl    time.Duration
}

// å¤šå±‚ç¼“å­˜ç­–ç•¥
func (c *SearchCache) Get(key string) (*SearchResult, bool) {
    // L1: å†…å­˜ç¼“å­˜ (æœ€å¿«)
    if result, ok := c.local.Load(key); ok {
        return result.(*SearchResult), true
    }

    // L2: Redis ç¼“å­˜ (ä¸­ç­‰)
    if cached, err := c.redis.Get(ctx, key).Result(); err == nil {
        var result SearchResult
        json.Unmarshal([]byte(cached), &result)
        c.local.Store(key, &result) // å›å¡« L1
        return &result, true
    }

    return nil, false
}
```

#### æ‰¹é‡æœç´¢

```go
// æ‰¹é‡å¤„ç†å¤šä¸ªæœç´¢æŸ¥è¯¢
func (s *SearchEngine) BatchSearch(ctx context.Context, queries []string) ([]*SearchResponse, error) {
    // 1. æ‰¹é‡ç”ŸæˆæŸ¥è¯¢å‘é‡
    queryVectors, err := s.embedder.EmbedBatch(ctx, queries)

    // 2. å¹¶è¡Œæ‰§è¡Œæœç´¢
    var wg sync.WaitGroup
    results := make([]*SearchResponse, len(queries))

    for i, query := range queries {
        wg.Add(1)
        go func(idx int, q string) {
            defer wg.Done()
            results[idx], _ = s.SingleSearch(ctx, q, queryVectors[idx])
        }(i, query)
    }

    wg.Wait()
    return results, nil
}
```

### 2. å†…å­˜ä¼˜åŒ–

#### æµå¼å¤„ç†

```go
// æµå¼å¤„ç†å¤§é‡æœç´¢ç»“æœ
func (s *SearchEngine) StreamSearch(ctx context.Context, req SearchRequest) (<-chan SearchResult, error) {
    resultChan := make(chan SearchResult, 100)

    go func() {
        defer close(resultChan)

        // åˆ†é¡µå¤„ç†é¿å…å†…å­˜å³°å€¼
        pageSize := 1000
        for offset := 0; ; offset += pageSize {
            batch, err := s.searchBatch(ctx, req, offset, pageSize)
            if err != nil || len(batch) == 0 {
                break
            }

            for _, result := range batch {
                select {
                case resultChan <- result:
                case <-ctx.Done():
                    return
                }
            }
        }
    }()

    return resultChan, nil
}
```

### 3. å‘é‡åŒ–ä¼˜åŒ–

#### æ–‡æœ¬é¢„å¤„ç†

```go
type TextPreprocessor struct {
    chunker    *TextChunker
    cleaner    *TextCleaner
    tokenizer  *Tokenizer
}

// ä¼˜åŒ–æ–‡æœ¬åˆ†å—ç­–ç•¥
func (p *TextPreprocessor) ProcessText(text string, maxTokens int) []string {
    // 1. æ–‡æœ¬æ¸…æ´—
    cleaned := p.cleaner.Clean(text)

    // 2. æ™ºèƒ½åˆ†å— (ä¿æŒè¯­ä¹‰å®Œæ•´æ€§)
    chunks := p.chunker.ChunkWithOverlap(cleaned, maxTokens, 0.1)

    // 3. è´¨é‡è¿‡æ»¤
    filtered := p.filterLowQualityChunks(chunks)

    return filtered
}

// è´¨é‡è¿‡æ»¤æ ‡å‡†
func (p *TextPreprocessor) filterLowQualityChunks(chunks []string) []string {
    var result []string
    for _, chunk := range chunks {
        if len(chunk) < 50 ||
           strings.Count(chunk, " ") < 5 ||
           p.hasRepetitiveContent(chunk) {
            continue
        }
        result = append(result, chunk)
    }
    return result
}
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### å…³é”®æŒ‡æ ‡

#### 1. æœç´¢æ€§èƒ½æŒ‡æ ‡

```go
var (
    searchDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "vector_search_duration_seconds",
            Help:    "Duration of vector search operations",
            Buckets: prometheus.DefBuckets,
        },
        []string{"user_id", "query_length"},
    )

    cacheHitRate = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "search_cache_hits_total",
            Help: "Total number of search cache hits",
        },
        []string{"cache_level"},
    )

    indexUsage = prometheus.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "vector_index_usage_ratio",
            Help: "Ratio of index usage in vector queries",
        },
        []string{"index_type"},
    )
)
```

#### 2. æ•°æ®åº“ç›‘æ§

```sql
-- ç›‘æ§å‘é‡ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE tablename = 'email_embeddings';

-- ç›‘æ§æŸ¥è¯¢æ€§èƒ½
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    rows
FROM pg_stat_statements
WHERE query LIKE '%vector%'
ORDER BY total_exec_time DESC;
```

### æ€§èƒ½åŸºå‡†

#### æœç´¢å»¶è¿ŸåŸºå‡†

| æ•°æ®é‡ | ç»´åº¦ | ç´¢å¼•ç±»å‹ | P50 å»¶è¿Ÿ | P99 å»¶è¿Ÿ | QPS |
|--------|------|----------|----------|----------|-----|
| 10ä¸‡   | 768  | IVFFlat  | 15ms     | 45ms     | 200 |
| 100ä¸‡  | 768  | IVFFlat  | 25ms     | 80ms     | 150 |
| 1000ä¸‡ | 768  | HNSW     | 35ms     | 120ms    | 100 |
| 10ä¸‡   | 1536 | IVFFlat  | 20ms     | 60ms     | 180 |
| 100ä¸‡  | 1536 | HNSW     | 30ms     | 100ms    | 120 |

#### å­˜å‚¨æ€§èƒ½åŸºå‡†

| ç»´åº¦ | æ¯å‘é‡å¤§å° | 100ä¸‡å‘é‡å­˜å‚¨ | ç´¢å¼•å¤§å° | æœç´¢å†…å­˜ |
|------|------------|----------------|----------|----------|
| 768  | 3KB        | 3GB            | 500MB    | 200MB    |
| 1024 | 4KB        | 4GB            | 700MB    | 300MB    |
| 1536 | 6KB        | 6GB            | 1.2GB    | 500MB    |

## ğŸ”§ é…ç½®æœ€ä½³å®è·µ

### 1. ç¯å¢ƒé…ç½®

```yaml
# config.yaml
database:
  # è¿æ¥æ± ä¼˜åŒ–
  max_open_conns: 25
  max_idle_conns: 5
  conn_max_lifetime: 300s

vector:
  # ç´¢å¼•é…ç½®
  index_type: "hnsw"  # ivfflat æˆ– hnsw
  hnsw:
    m: 16
    ef_construction: 64
  ivfflat:
    lists: 100

search:
  # æœç´¢é…ç½®
  default_limit: 20
  max_limit: 100
  cache_ttl: 1800s  # 30åˆ†é’Ÿ

embedding:
  # åµŒå…¥é…ç½®
  batch_size: 32
  chunk_size: 1000
  overlap_ratio: 0.1
```

### 2. ç”Ÿäº§ç¯å¢ƒè°ƒä¼˜

```sql
-- PostgreSQL é…ç½®ä¼˜åŒ–
-- postgresql.conf
shared_buffers = 2GB                    -- 25% of RAM
effective_cache_size = 6GB              -- 75% of RAM
work_mem = 64MB                         -- Per query memory
maintenance_work_mem = 256MB
random_page_cost = 1.1                  -- SSD optimization
seq_page_cost = 1.0

-- pgvector ç‰¹å®šä¼˜åŒ–
hnsw.ef_search = 100                    -- Higher ef for better recall
ivfflat.probes = 10                     -- Number of probes to examine
```

## ğŸ§ª æµ‹è¯•å’Œè°ƒè¯•

### 1. å•å…ƒæµ‹è¯•

```go
func TestVectorSearch(t *testing.T) {
    // å‡†å¤‡æµ‹è¯•æ•°æ®
    testVectors := generateTestVectors(1000, 768)

    // æ’å…¥æµ‹è¯•æ•°æ®
    for _, vec := range testVectors {
        db.Create(&EmailEmbedding{
            Vector: pgvector.NewVector(vec),
        })
    }

    // æ‰§è¡Œæœç´¢æµ‹è¯•
    query := generateTestVector(768)
    results, err := searchEngine.Search(query, 10)

    assert.NoError(t, err)
    assert.Len(t, results, 10)

    // éªŒè¯ç›¸ä¼¼åº¦æ’åº
    for i := 1; i < len(results); i++ {
        assert.GreaterOrEqual(t, results[i-1].Score, results[i].Score)
    }
}
```

### 2. é›†æˆæµ‹è¯•

```go
func TestSearchPerformance(t *testing.T) {
    // æ€§èƒ½åŸºå‡†æµ‹è¯•
    b := testing.B{}

    for i := 0; i < b.N; i++ {
        start := time.Now()
        _, err := searchEngine.SemanticSearch(ctx, SearchRequest{
            Query: "test query",
            Limit: 20,
        })
        duration := time.Since(start)

        // è®°å½•æ€§èƒ½æŒ‡æ ‡
        prometheus.RecordDuration(duration)

        assert.NoError(t, err)
        assert.Less(t, duration, 100*time.Millisecond)
    }
}
```

### 3. è°ƒè¯•å·¥å…·

```go
// æœç´¢è°ƒè¯•å·¥å…·
type SearchDebugger struct {
    logger *log.Logger
}

func (d *SearchDebugger) DebugSearch(ctx context.Context, query string) {
    d.logger.Printf("=== Search Debug ===")
    d.logger.Printf("Query: %s", query)

    // 1. è®°å½•æŸ¥è¯¢å‘é‡
    vector, _ := d.embedder.Embed(ctx, query)
    d.logger.Printf("Query vector dimensions: %d", len(vector))

    // 2. è®°å½•æŸ¥è¯¢è®¡åˆ’
    var explain []string
    db.Raw("EXPLAIN (ANALYZE, BUFFERS) " + searchSQL, vector).Scan(&explain)
    d.logger.Printf("Query plan: %v", explain)

    // 3. è®°å½•æœç´¢ç»“æœ
    results, _ := d.searchEngine.Search(ctx, query, 5)
    d.logger.Printf("Results count: %d", len(results))
    for i, result := range results {
        d.logger.Printf("Result %d: score=%.4f, id=%s", i, result.Score, result.ID)
    }
}
```

## ğŸš€ æœªæ¥ä¼˜åŒ–æ–¹å‘

### 1. é«˜çº§ç´¢å¼•ç­–ç•¥
- **DiskANN**: æ›´å¤§è§„æ¨¡çš„å‘é‡ç´¢å¼•
- **Quantization**: å‘é‡é‡åŒ–å‡å°‘å­˜å‚¨ç©ºé—´
- **Hybrid Search**: ç»“åˆå…³é”®è¯æœç´¢å’Œå‘é‡æœç´¢

### 2. æ™ºèƒ½ç¼“å­˜
- **LRU Cache**: æ›´æ™ºèƒ½çš„ç¼“å­˜ç­–ç•¥
- **Prefetching**: åŸºäºç”¨æˆ·è¡Œä¸ºçš„é¢„å–
- **Distributed Cache**: Redis Cluster æ”¯æŒ

### 3. å®æ—¶ä¼˜åŒ–
- **Online Learning**: åŸºäºç”¨æˆ·åé¦ˆçš„å®æ—¶ä¼˜åŒ–
- **A/B Testing**: ä¸åŒæœç´¢ç®—æ³•çš„å¯¹æ¯”æµ‹è¯•
- **Auto-tuning**: è‡ªåŠ¨è°ƒæ•´æœç´¢å‚æ•°

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­ï¼Œæœ€åæ›´æ–°æ—¶é—´: 2025-11-25*